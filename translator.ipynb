{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a138f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e036f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 97568 English sentences\n",
      "Loaded 97568 Russian sentences\n",
      "\n",
      "Example pair:\n",
      "EN: For once in my life I'm doing a good deed... And it is useless.\n",
      "RU: Один раз в жизни я делаю хорошее дело... И оно бесполезно.\n"
     ]
    }
   ],
   "source": [
    "# Load the English-Russian parallel text data\n",
    "with open('data/Tatoeba.en-ru.en', 'r', encoding='utf-8') as f:\n",
    "    en_texts = f.read().strip().split('\\n')\n",
    "\n",
    "with open('data/Tatoeba.en-ru.ru', 'r', encoding='utf-8') as f:\n",
    "    ru_texts = f.read().strip().split('\\n')\n",
    "\n",
    "print(f\"Loaded {len(en_texts)} English sentences\")\n",
    "print(f\"Loaded {len(ru_texts)} Russian sentences\")\n",
    "print(f\"\\nExample pair:\")\n",
    "print(f\"EN: {en_texts[0]}\")\n",
    "print(f\"RU: {ru_texts[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581a19ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size: 157\n",
      "Russian vocab size: 192\n"
     ]
    }
   ],
   "source": [
    "en_chars = sorted(list(set(''.join(en_texts))))\n",
    "ru_chars = sorted(list(set(''.join(ru_texts))))\n",
    "\n",
    "SOS_TOKEN = '<SOS>'\n",
    "EOS_TOKEN = '<EOS>'\n",
    "PAD_TOKEN = '<PAD>'\n",
    "\n",
    "en_chars = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN] + en_chars\n",
    "ru_chars = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN] + ru_chars\n",
    "\n",
    "en_vocab_size = len(en_chars)\n",
    "ru_vocab_size = len(ru_chars)\n",
    "\n",
    "print(f\"English vocab size: {en_vocab_size}\")\n",
    "print(f\"Russian vocab size: {ru_vocab_size}\")\n",
    "\n",
    "en_stoi = {ch: i for i, ch in enumerate(en_chars)}\n",
    "en_itos = {i: ch for i, ch in enumerate(en_chars)}\n",
    "ru_stoi = {ch: i for i, ch in enumerate(ru_chars)}\n",
    "ru_itos = {i: ch for i, ch in enumerate(ru_chars)}\n",
    "\n",
    "def encode_en(s):\n",
    "    return [en_stoi[SOS_TOKEN]] + [en_stoi[c] for c in s] + [en_stoi[EOS_TOKEN]]\n",
    "\n",
    "def encode_ru(s):\n",
    "    return [ru_stoi[SOS_TOKEN]] + [ru_stoi[c] for c in s] + [ru_stoi[EOS_TOKEN]]\n",
    "\n",
    "def decode_en(l):\n",
    "    return ''.join([en_itos[i] for i in l if i not in [en_stoi[PAD_TOKEN], en_stoi[SOS_TOKEN], en_stoi[EOS_TOKEN]]])\n",
    "\n",
    "def decode_ru(l):\n",
    "    return ''.join([ru_itos[i] for i in l if i not in [ru_stoi[PAD_TOKEN], ru_stoi[SOS_TOKEN], ru_stoi[EOS_TOKEN]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938d7246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "embd_dim = 256\n",
    "max_seq_length = 128\n",
    "batch_size = 64\n",
    "n_heads = 8\n",
    "n_layers = 8\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dropout = 0.1\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33a0531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 97005 pairs (filtered by max length)\n",
      "Train pairs: 87304\n",
      "Val pairs: 9701\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(en_texts, ru_texts, max_len):\n",
    "    pairs = []\n",
    "    for en, ru in zip(en_texts, ru_texts):\n",
    "        en_encoded = encode_en(en)\n",
    "        ru_encoded = encode_ru(ru)\n",
    "        \n",
    "        if len(en_encoded) > max_len or len(ru_encoded) > max_len:\n",
    "            continue\n",
    "            \n",
    "        pairs.append((en_encoded, ru_encoded))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "pairs = prepare_data(en_texts, ru_texts, max_seq_length)\n",
    "print(f\"Prepared {len(pairs)} pairs (filtered by max length)\")\n",
    "\n",
    "split_idx = int(len(pairs) * 0.9)\n",
    "train_pairs = pairs[:split_idx]\n",
    "val_pairs = pairs[split_idx:]\n",
    "\n",
    "print(f\"Train pairs: {len(train_pairs)}\")\n",
    "print(f\"Val pairs: {len(val_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206516a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(pairs, batch_size, device):\n",
    "    indices = torch.randint(len(pairs), (batch_size,))\n",
    "    \n",
    "    src_batch = []\n",
    "    tgt_batch = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        src, tgt = pairs[idx]\n",
    "        src_batch.append(src)\n",
    "        tgt_batch.append(tgt)\n",
    "    \n",
    "    max_src_len = max(len(s) for s in src_batch)\n",
    "    max_tgt_len = max(len(t) for t in tgt_batch)\n",
    "    \n",
    "    src_padded = torch.full((batch_size, max_src_len), en_stoi[PAD_TOKEN], dtype=torch.long)\n",
    "    tgt_padded = torch.full((batch_size, max_tgt_len), ru_stoi[PAD_TOKEN], dtype=torch.long)\n",
    "    \n",
    "    for i, (src, tgt) in enumerate(zip(src_batch, tgt_batch)):\n",
    "        src_padded[i, :len(src)] = torch.tensor(src)\n",
    "        tgt_padded[i, :len(tgt)] = torch.tensor(tgt)\n",
    "   \n",
    "    tgt_input = tgt_padded[:, :-1]\n",
    "    tgt_output = tgt_padded[:, 1:]\n",
    "    \n",
    "    return src_padded.to(device), tgt_input.to(device), tgt_output.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede872b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import InputEmbedding, DecoderBlock, CrossMultiHead, EncoderBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8903362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, embd_dim, max_seq_length, n_heads, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embeddings\n",
    "        self.src_embedding = InputEmbedding(src_vocab_size, embd_dim, max_seq_length)\n",
    "        self.tgt_embedding = InputEmbedding(tgt_vocab_size, embd_dim, max_seq_length)\n",
    "        \n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderBlock(embd_dim, n_heads, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderBlock(embd_dim, n_heads, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.cross_attention_layers = nn.ModuleList([\n",
    "            CrossMultiHead(embd_dim, n_heads, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.cross_ln = nn.ModuleList([\n",
    "            nn.LayerNorm(embd_dim) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.ln_out = nn.LayerNorm(embd_dim)\n",
    "        self.output_proj = nn.Linear(embd_dim, tgt_vocab_size)\n",
    "        \n",
    "    def encode(self, src):\n",
    "        x = self.src_embedding(src)\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, tgt, enc_output):\n",
    "        x = self.tgt_embedding(tgt)\n",
    "        for decoder_layer, cross_attn, cross_ln in zip(\n",
    "            self.decoder_layers, self.cross_attention_layers, self.cross_ln\n",
    "        ):\n",
    "            x = decoder_layer(x)\n",
    "            x = x + cross_attn(enc_output, cross_ln(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        enc_output = self.encode(src)\n",
    "        dec_output = self.decode(tgt, enc_output)\n",
    "        logits = self.output_proj(self.ln_out(dec_output))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3829b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(targets, logits):\n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.reshape(B * T, C)\n",
    "    targets = targets.reshape(B * T)\n",
    "    \n",
    "    loss = F.cross_entropy(logits, targets, ignore_index=ru_stoi[PAD_TOKEN])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "619714d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 14,931,904\n"
     ]
    }
   ],
   "source": [
    "model = Seq2SeqTransformer(\n",
    "    src_vocab_size=en_vocab_size,\n",
    "    tgt_vocab_size=ru_vocab_size,\n",
    "    embd_dim=embd_dim,\n",
    "    max_seq_length=max_seq_length,\n",
    "    n_heads=n_heads,\n",
    "    n_layers=n_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c58f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_checkpoint(model, optimizer, step, train_loss, val_loss, checkpoint_dir='checkpoints'):\n",
    "    \"\"\"Save model checkpoint with training state\"\"\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    checkpoint = {\n",
    "        'step': step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'config': {\n",
    "            'src_vocab_size': en_vocab_size,\n",
    "            'tgt_vocab_size': ru_vocab_size,\n",
    "            'embd_dim': embd_dim,\n",
    "            'max_seq_length': max_seq_length,\n",
    "            'n_heads': n_heads,\n",
    "            'n_layers': n_layers,\n",
    "            'dropout': dropout\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_step_{step}.pt')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    \n",
    "    latest_path = os.path.join(checkpoint_dir, 'checkpoint_latest.pt')\n",
    "    torch.save(checkpoint, latest_path)\n",
    "    \n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "    return checkpoint_path\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_path, model, optimizer=None):\n",
    "    \"\"\"Load model checkpoint and restore training state\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    step = checkpoint.get('step', 0)\n",
    "    train_loss = checkpoint.get('train_loss', 0.0)\n",
    "    val_loss = checkpoint.get('val_loss', 0.0)\n",
    "    \n",
    "    print(f\"Checkpoint loaded from: {checkpoint_path}\")\n",
    "    print(f\"Resuming from step: {step}\")\n",
    "    print(f\"Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return step, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca812cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:     0  train loss: 5.3553  val loss: 4.2959\n",
      "Checkpoint saved: checkpoints/checkpoint_step_100.pt\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_steps = 15000\n",
    "eval_interval = 200\n",
    "checkpoint_interval = 1000\n",
    "model.train()\n",
    "\n",
    "for step in range(num_steps):\n",
    "    src, tgt_input, tgt_output = get_batch(train_pairs, batch_size, device)\n",
    "    \n",
    "    logits = model(src, tgt_input)\n",
    "    loss = compute_loss(tgt_output, logits)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % eval_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            src_val, tgt_input_val, tgt_output_val = get_batch(val_pairs, batch_size, device)\n",
    "            logits_val = model(src_val, tgt_input_val)\n",
    "            val_loss = compute_loss(tgt_output_val, logits_val)\n",
    "        \n",
    "        print(f\"step: {step:5d}  train loss: {loss.item():.4f}  val loss: {val_loss.item():.4f}\")\n",
    "        model.train()\n",
    "    \n",
    "    if step % checkpoint_interval == 0 and step > 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            src_val, tgt_input_val, tgt_output_val = get_batch(val_pairs, batch_size, device)\n",
    "            logits_val = model(src_val, tgt_input_val)\n",
    "            val_loss = compute_loss(tgt_output_val, logits_val)\n",
    "        save_checkpoint(model, optimizer, step, loss.item(), val_loss.item())\n",
    "        model.train()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    src_val, tgt_input_val, tgt_output_val = get_batch(val_pairs, batch_size, device)\n",
    "    logits_val = model(src_val, tgt_input_val)\n",
    "    val_loss = compute_loss(tgt_output_val, logits_val)\n",
    "save_checkpoint(model, optimizer, num_steps, loss.item(), val_loss.item())\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e641fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: checkpoints/checkpoint_latest.pt\n",
      "Resuming from step: 100\n",
      "Train loss: 2.4796, Val loss: 2.4786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11284/3074988078.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'checkpoints/checkpoint_latest.pt'  # or specify a specific checkpoint\n",
    "step, train_loss, val_loss = load_checkpoint(checkpoint_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22a19d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation Examples:\n",
      "\n",
      "EN: Hello, how are you?\n",
      "RU: Каш я.\n",
      "\n",
      "EN: I love learning languages.\n",
      "RU: Я нидне уловене ол утишерогоровок тые вем, каим?\n",
      "\n",
      "EN: Today is a beautiful day.\n",
      "RU: Не помолякряконе овсверороселе денах родах ралинёпосве малокатси.\n",
      "\n",
      "EN: Let's try something.\n",
      "RU: Давалче повт Я працила бутшокаточеместакега по.\n",
      "\n",
      "EN: I will be back soon.\n",
      "RU: Мы МЯ коефрибы низаналавини вовим вть ка ченый пукущерери мы н прололь окавобу.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def translate(model, en_text, max_len=max_seq_length, temperature=1.0):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        src_tokens = encode_en(en_text)\n",
    "        if len(src_tokens) > max_len:\n",
    "            src_tokens = src_tokens[:max_len]\n",
    "        \n",
    "        src = torch.tensor(src_tokens, device=device).unsqueeze(0)  # [1, T]\n",
    "        \n",
    "        enc_output = model.encode(src)\n",
    "        tgt = torch.tensor([[ru_stoi[SOS_TOKEN]]], device=device)\n",
    "        \n",
    "        for _ in range(max_len):\n",
    "            dec_output = model.decode(tgt, enc_output)\n",
    "            logits = model.output_proj(model.ln_out(dec_output))\n",
    "            \n",
    "            next_logits = logits[0, -1, :] / temperature\n",
    "            probs = F.softmax(next_logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            if next_token.item() == ru_stoi[EOS_TOKEN]:\n",
    "                break\n",
    "            \n",
    "            tgt = torch.cat([tgt, next_token.unsqueeze(0)], dim=1)\n",
    "        \n",
    "        translated = decode_ru(tgt[0].tolist())\n",
    "        return translated\n",
    "\n",
    "\n",
    "print(\"Translation Examples:\\n\")\n",
    "test_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I love learning languages.\",\n",
    "    \"Today is a beautiful day.\",\n",
    "    \"Let's try something.\",\n",
    "    \"I will be back soon.\"\n",
    "]\n",
    "\n",
    "for en_text in test_sentences:\n",
    "    translation = translate(model, en_text, temperature=0.8)\n",
    "    print(f\"EN: {en_text}\")\n",
    "    print(f\"RU: {translation}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "970cc78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Examples with Ground Truth:\n",
      "\n",
      "EN:        What are you doing with your life?\n",
      "RU (true): Что ты делаешь со своей жизнью?\n",
      "RU (pred): Ты де побу пигорашисть денела буду.\n",
      "\n",
      "EN:        He can nourish his elephant, but cannot nourish his child.\n",
      "RU (true): Он может прокормить своего слона, но не может прокормить своего ребёнка.\n",
      "RU (pred): Он тобы почто нано пови роретего прамоераня ти этибенестодна полваюе х повизанови вать пологоголих вавлой в якащетинемо порнось \n",
      "\n",
      "EN:        I'm late a little.\n",
      "RU (true): Я немного опоздал.\n",
      "RU (pred): Я здаль точто до полеродитито побом водедемистсто столоваридашь понако пренеленом вемане да поди в детов.\n",
      "\n",
      "EN:        Do not step on a dog's tail.\n",
      "RU (true): Не наступайте собаке на хвост.\n",
      "RU (pred): В не мобы, к нанего поре то ночтобы нее туза, стьдеть покиздо да сята вама помотерех ть по ни в честомна.\n",
      "\n",
      "EN:        He who is bitten by a snake fears even the rope.\n",
      "RU (true): Обжёгшись на молоке, на воду дуют.\n",
      "RU (pred): Это сого веробы столови лра продематрака в ралецатьченограниза ко не покастобе ве пов недо фресенином в ко притстримало какитено\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Examples with Ground Truth:\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    src, tgt = val_pairs[i]\n",
    "    en_text = decode_en(src)\n",
    "    ru_true = decode_ru(tgt)\n",
    "    ru_pred = translate(model, en_text, temperature=0.5)\n",
    "    \n",
    "    print(f\"EN:        {en_text}\")\n",
    "    print(f\"RU (true): {ru_true}\")\n",
    "    print(f\"RU (pred): {ru_pred}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
