{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a138f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e036f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 540674 English sentences\n",
      "Loaded 540674 Russian sentences\n",
      "\n",
      "Example pair:\n",
      "EN: For once in my life I'm doing a good deed... And it is useless. \n",
      "RU: Один раз в жизни я делаю хорошее дело... И оно бесполезно. \n"
     ]
    }
   ],
   "source": [
    "# Load the English-Russian parallel text data\n",
    "with open('data/Tatoeba.en-ru.en', 'r', encoding='utf-8') as f:\n",
    "    en_texts = f.read().strip().split('\\n')\n",
    "\n",
    "with open('data/Tatoeba.en-ru.ru', 'r', encoding='utf-8') as f:\n",
    "    ru_texts = f.read().strip().split('\\n')\n",
    "\n",
    "print(f\"Loaded {len(en_texts)} English sentences\")\n",
    "print(f\"Loaded {len(ru_texts)} Russian sentences\")\n",
    "print(f\"\\nExample pair:\")\n",
    "print(f\"EN: {en_texts[0]}\")\n",
    "print(f\"RU: {ru_texts[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a19ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size: 223\n",
      "Russian vocab size: 231\n"
     ]
    }
   ],
   "source": [
    "en_chars = sorted(list(set(''.join(en_texts))))\n",
    "ru_chars = sorted(list(set(''.join(ru_texts))))\n",
    "\n",
    "SOS_TOKEN = '<SOS>'\n",
    "EOS_TOKEN = '<EOS>'\n",
    "PAD_TOKEN = '<PAD>'\n",
    "\n",
    "en_chars = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN] + en_chars\n",
    "ru_chars = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN] + ru_chars\n",
    "\n",
    "en_vocab_size = len(en_chars)\n",
    "ru_vocab_size = len(ru_chars)\n",
    "\n",
    "print(f\"English vocab size: {en_vocab_size}\")\n",
    "print(f\"Russian vocab size: {ru_vocab_size}\")\n",
    "\n",
    "en_stoi = {ch: i for i, ch in enumerate(en_chars)}\n",
    "en_itos = {i: ch for i, ch in enumerate(en_chars)}\n",
    "ru_stoi = {ch: i for i, ch in enumerate(ru_chars)}\n",
    "ru_itos = {i: ch for i, ch in enumerate(ru_chars)}\n",
    "\n",
    "def encode_en(s):\n",
    "    return [en_stoi[SOS_TOKEN]] + [en_stoi[c] for c in s] + [en_stoi[EOS_TOKEN]]\n",
    "\n",
    "def encode_ru(s):\n",
    "    return [ru_stoi[SOS_TOKEN]] + [ru_stoi[c] for c in s] + [ru_stoi[EOS_TOKEN]]\n",
    "\n",
    "def decode_en(l):\n",
    "    return ''.join([en_itos[i] for i in l if i not in [en_stoi[PAD_TOKEN], en_stoi[SOS_TOKEN], en_stoi[EOS_TOKEN]]])\n",
    "\n",
    "def decode_ru(l):\n",
    "    return ''.join([ru_itos[i] for i in l if i not in [ru_stoi[PAD_TOKEN], ru_stoi[SOS_TOKEN], ru_stoi[EOS_TOKEN]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938d7246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "embd_dim = 256\n",
    "max_seq_length = 128\n",
    "batch_size = 64\n",
    "n_heads = 8\n",
    "n_layers = 8\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dropout = 0.1\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a0531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 538850 pairs (filtered by max length)\n",
      "Train pairs: 484965\n",
      "Val pairs: 53885\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(en_texts, ru_texts, max_len):\n",
    "    pairs = []\n",
    "    for en, ru in zip(en_texts, ru_texts):\n",
    "        en_encoded = encode_en(en)\n",
    "        ru_encoded = encode_ru(ru)\n",
    "        \n",
    "        if len(en_encoded) > max_len or len(ru_encoded) > max_len:\n",
    "            continue\n",
    "            \n",
    "        pairs.append((en_encoded, ru_encoded))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "pairs = prepare_data(en_texts, ru_texts, max_seq_length)\n",
    "print(f\"Prepared {len(pairs)} pairs (filtered by max length)\")\n",
    "\n",
    "split_idx = int(len(pairs) * 0.9)\n",
    "train_pairs = pairs[:split_idx]\n",
    "val_pairs = pairs[split_idx:]\n",
    "\n",
    "print(f\"Train pairs: {len(train_pairs)}\")\n",
    "print(f\"Val pairs: {len(val_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206516a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(pairs, batch_size, device):\n",
    "    indices = torch.randint(len(pairs), (batch_size,))\n",
    "    \n",
    "    src_batch = []\n",
    "    tgt_batch = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        src, tgt = pairs[idx]\n",
    "        src_batch.append(src)\n",
    "        tgt_batch.append(tgt)\n",
    "    \n",
    "    max_src_len = max(len(s) for s in src_batch)\n",
    "    max_tgt_len = max(len(t) for t in tgt_batch)\n",
    "    \n",
    "    src_padded = torch.full((batch_size, max_src_len), en_stoi[PAD_TOKEN], dtype=torch.long)\n",
    "    tgt_padded = torch.full((batch_size, max_tgt_len), ru_stoi[PAD_TOKEN], dtype=torch.long)\n",
    "    \n",
    "    for i, (src, tgt) in enumerate(zip(src_batch, tgt_batch)):\n",
    "        src_padded[i, :len(src)] = torch.tensor(src)\n",
    "        tgt_padded[i, :len(tgt)] = torch.tensor(tgt)\n",
    "   \n",
    "    tgt_input = tgt_padded[:, :-1]\n",
    "    tgt_output = tgt_padded[:, 1:]\n",
    "    \n",
    "    return src_padded.to(device), tgt_input.to(device), tgt_output.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede872b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import InputEmbedding, DecoderBlock, CrossMultiHead, EncoderBlock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, embd_dim, max_seq_length, n_heads, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embeddings\n",
    "        self.src_embedding = InputEmbedding(src_vocab_size, embd_dim, max_seq_length)\n",
    "        self.tgt_embedding = InputEmbedding(tgt_vocab_size, embd_dim, max_seq_length)\n",
    "        \n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderBlock(embd_dim, n_heads, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderBlock(embd_dim, n_heads, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.cross_attention_layers = nn.ModuleList([\n",
    "            CrossMultiHead(embd_dim, n_heads, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.cross_ln = nn.ModuleList([\n",
    "            nn.LayerNorm(embd_dim) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.ln_out = nn.LayerNorm(embd_dim)\n",
    "        self.output_proj = nn.Linear(embd_dim, tgt_vocab_size)\n",
    "        \n",
    "    def encode(self, src):\n",
    "        x = self.src_embedding(src)\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, tgt, enc_output):\n",
    "        x = self.tgt_embedding(tgt)\n",
    "        for decoder_layer, cross_attn, cross_ln in zip(\n",
    "            self.decoder_layers, self.cross_attention_layers, self.cross_ln\n",
    "        ):\n",
    "            x = decoder_layer(x)\n",
    "            x = x + cross_attn(enc_output, cross_ln(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        enc_output = self.encode(src)\n",
    "        dec_output = self.decode(tgt, enc_output)\n",
    "        logits = self.output_proj(self.ln_out(dec_output))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3829b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(targets, logits):\n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.reshape(B * T, C)\n",
    "    targets = targets.reshape(B * T)\n",
    "    \n",
    "    loss = F.cross_entropy(logits, targets, ignore_index=ru_stoi[PAD_TOKEN])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619714d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 14,968,807\n"
     ]
    }
   ],
   "source": [
    "model = Seq2SeqTransformer(\n",
    "    src_vocab_size=en_vocab_size,\n",
    "    tgt_vocab_size=ru_vocab_size,\n",
    "    embd_dim=embd_dim,\n",
    "    max_seq_length=max_seq_length,\n",
    "    n_heads=n_heads,\n",
    "    n_layers=n_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_checkpoint(model, optimizer, step, train_loss, val_loss, checkpoint_dir='checkpoints'):\n",
    "    \"\"\"Save model checkpoint with training state\"\"\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    checkpoint = {\n",
    "        'step': step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'config': {\n",
    "            'src_vocab_size': en_vocab_size,\n",
    "            'tgt_vocab_size': ru_vocab_size,\n",
    "            'embd_dim': embd_dim,\n",
    "            'max_seq_length': max_seq_length,\n",
    "            'n_heads': n_heads,\n",
    "            'n_layers': n_layers,\n",
    "            'dropout': dropout\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_step_{step}.pt')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    \n",
    "    latest_path = os.path.join(checkpoint_dir, 'checkpoint_latest.pt')\n",
    "    torch.save(checkpoint, latest_path)\n",
    "    \n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "    return checkpoint_path\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_path, model, optimizer=None):\n",
    "    \"\"\"Load model checkpoint and restore training state\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    step = checkpoint.get('step', 0)\n",
    "    train_loss = checkpoint.get('train_loss', 0.0)\n",
    "    val_loss = checkpoint.get('val_loss', 0.0)\n",
    "    \n",
    "    print(f\"Checkpoint loaded from: {checkpoint_path}\")\n",
    "    print(f\"Resuming from step: {step}\")\n",
    "    print(f\"Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return step, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca812cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:     0  train loss: 5.6714  val loss: 4.4644\n",
      "step:   200  train loss: 2.0392  val loss: 2.0664\n",
      "step:   400  train loss: 1.7420  val loss: 1.8793\n",
      "step:   600  train loss: 1.5836  val loss: 1.5922\n",
      "step:   800  train loss: 1.3906  val loss: 1.4513\n",
      "step:  1000  train loss: 1.3544  val loss: 1.3768\n",
      "Checkpoint saved: checkpoints/checkpoint_step_1000.pt\n",
      "step:  1200  train loss: 1.2802  val loss: 1.3216\n",
      "step:  1400  train loss: 1.3317  val loss: 1.2123\n",
      "step:  1600  train loss: 1.1548  val loss: 1.1505\n",
      "step:  1800  train loss: 1.0824  val loss: 1.2346\n",
      "step:  2000  train loss: 1.0821  val loss: 1.2251\n",
      "Checkpoint saved: checkpoints/checkpoint_step_2000.pt\n",
      "step:  2200  train loss: 1.1241  val loss: 1.1878\n",
      "step:  2400  train loss: 1.1403  val loss: 1.0965\n",
      "step:  2600  train loss: 1.1245  val loss: 1.0006\n",
      "step:  2800  train loss: 1.0171  val loss: 1.1429\n",
      "step:  3000  train loss: 0.8734  val loss: 1.1200\n",
      "Checkpoint saved: checkpoints/checkpoint_step_3000.pt\n",
      "step:  3200  train loss: 0.9823  val loss: 1.0413\n",
      "step:  3400  train loss: 0.9049  val loss: 1.0507\n",
      "step:  3600  train loss: 1.0422  val loss: 0.9161\n",
      "step:  3800  train loss: 0.9014  val loss: 0.9486\n",
      "step:  4000  train loss: 0.7886  val loss: 0.8991\n",
      "Checkpoint saved: checkpoints/checkpoint_step_4000.pt\n",
      "step:  4200  train loss: 0.7973  val loss: 1.0249\n",
      "step:  4400  train loss: 0.8127  val loss: 0.8475\n",
      "step:  4600  train loss: 0.8397  val loss: 0.8370\n",
      "step:  4800  train loss: 0.7648  val loss: 0.9286\n",
      "step:  5000  train loss: 0.9362  val loss: 0.8575\n",
      "Checkpoint saved: checkpoints/checkpoint_step_5000.pt\n",
      "step:  5200  train loss: 0.8042  val loss: 0.9113\n",
      "step:  5400  train loss: 0.7966  val loss: 0.8271\n",
      "step:  5600  train loss: 0.8797  val loss: 0.9029\n",
      "step:  5800  train loss: 0.6562  val loss: 0.7984\n",
      "step:  6000  train loss: 0.6907  val loss: 0.7665\n",
      "Checkpoint saved: checkpoints/checkpoint_step_6000.pt\n",
      "step:  6200  train loss: 0.7997  val loss: 0.7561\n",
      "step:  6400  train loss: 0.8265  val loss: 0.7618\n",
      "step:  6600  train loss: 0.7812  val loss: 0.7778\n",
      "step:  6800  train loss: 0.6359  val loss: 0.9108\n",
      "step:  7000  train loss: 0.7319  val loss: 0.8290\n",
      "Checkpoint saved: checkpoints/checkpoint_step_7000.pt\n",
      "step:  7200  train loss: 0.7063  val loss: 0.6431\n",
      "step:  7400  train loss: 0.6366  val loss: 0.7478\n",
      "step:  7600  train loss: 0.6874  val loss: 0.7143\n",
      "step:  7800  train loss: 0.6297  val loss: 0.7104\n",
      "step:  8000  train loss: 0.6858  val loss: 0.6505\n",
      "Checkpoint saved: checkpoints/checkpoint_step_8000.pt\n",
      "step:  8200  train loss: 0.6870  val loss: 0.7865\n",
      "step:  8400  train loss: 0.6780  val loss: 0.7787\n",
      "step:  8600  train loss: 0.5335  val loss: 0.7024\n",
      "step:  8800  train loss: 0.5913  val loss: 0.7098\n",
      "step:  9000  train loss: 0.6520  val loss: 0.6936\n",
      "Checkpoint saved: checkpoints/checkpoint_step_9000.pt\n",
      "step:  9200  train loss: 0.5684  val loss: 0.5468\n",
      "step:  9400  train loss: 0.6473  val loss: 0.7760\n",
      "step:  9600  train loss: 0.5828  val loss: 0.7257\n",
      "step:  9800  train loss: 0.5692  val loss: 0.6437\n",
      "step: 10000  train loss: 0.5673  val loss: 0.8262\n",
      "Checkpoint saved: checkpoints/checkpoint_step_10000.pt\n",
      "step: 10200  train loss: 0.5638  val loss: 0.7097\n",
      "step: 10400  train loss: 0.6049  val loss: 0.7307\n",
      "step: 10600  train loss: 0.5068  val loss: 0.6959\n",
      "step: 10800  train loss: 0.6108  val loss: 0.5262\n",
      "step: 11000  train loss: 0.6036  val loss: 0.6997\n",
      "Checkpoint saved: checkpoints/checkpoint_step_11000.pt\n",
      "step: 11200  train loss: 0.6332  val loss: 0.5585\n",
      "step: 11400  train loss: 0.4955  val loss: 0.6650\n",
      "step: 11600  train loss: 0.4975  val loss: 0.6180\n",
      "step: 11800  train loss: 0.5058  val loss: 0.6143\n",
      "step: 12000  train loss: 0.4205  val loss: 0.5647\n",
      "Checkpoint saved: checkpoints/checkpoint_step_12000.pt\n",
      "step: 12200  train loss: 0.4687  val loss: 0.5400\n",
      "step: 12400  train loss: 0.4524  val loss: 0.5891\n",
      "step: 12600  train loss: 0.4669  val loss: 0.6011\n",
      "step: 12800  train loss: 0.4717  val loss: 0.4699\n",
      "step: 13000  train loss: 0.4408  val loss: 0.4601\n",
      "Checkpoint saved: checkpoints/checkpoint_step_13000.pt\n",
      "step: 13200  train loss: 0.5443  val loss: 0.6570\n",
      "step: 13400  train loss: 0.4130  val loss: 0.6730\n",
      "step: 13600  train loss: 0.4954  val loss: 0.5978\n",
      "step: 13800  train loss: 0.6344  val loss: 0.5470\n",
      "step: 14000  train loss: 0.3629  val loss: 0.5500\n",
      "Checkpoint saved: checkpoints/checkpoint_step_14000.pt\n",
      "step: 14200  train loss: 0.4361  val loss: 0.4777\n",
      "step: 14400  train loss: 0.4101  val loss: 0.5883\n",
      "step: 14600  train loss: 0.4567  val loss: 0.5820\n",
      "step: 14800  train loss: 0.4501  val loss: 0.5104\n",
      "Checkpoint saved: checkpoints/checkpoint_step_15000.pt\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_steps = 15000\n",
    "eval_interval = 200\n",
    "checkpoint_interval = 1000\n",
    "model.train()\n",
    "\n",
    "for step in range(num_steps):\n",
    "    src, tgt_input, tgt_output = get_batch(train_pairs, batch_size, device)\n",
    "    \n",
    "    logits = model(src, tgt_input)\n",
    "    loss = compute_loss(tgt_output, logits)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % eval_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            src_val, tgt_input_val, tgt_output_val = get_batch(val_pairs, batch_size, device)\n",
    "            logits_val = model(src_val, tgt_input_val)\n",
    "            val_loss = compute_loss(tgt_output_val, logits_val)\n",
    "        \n",
    "        print(f\"step: {step:5d}  train loss: {loss.item():.4f}  val loss: {val_loss.item():.4f}\")\n",
    "        model.train()\n",
    "    \n",
    "    if step % checkpoint_interval == 0 and step > 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            src_val, tgt_input_val, tgt_output_val = get_batch(val_pairs, batch_size, device)\n",
    "            logits_val = model(src_val, tgt_input_val)\n",
    "            val_loss = compute_loss(tgt_output_val, logits_val)\n",
    "        save_checkpoint(model, optimizer, step, loss.item(), val_loss.item())\n",
    "        model.train()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    src_val, tgt_input_val, tgt_output_val = get_batch(val_pairs, batch_size, device)\n",
    "    logits_val = model(src_val, tgt_input_val)\n",
    "    val_loss = compute_loss(tgt_output_val, logits_val)\n",
    "save_checkpoint(model, optimizer, num_steps, loss.item(), val_loss.item())\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e641fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5976/606622569.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: checkpoints/checkpoint_latest.pt\n",
      "Resuming from step: 15000\n",
      "Train loss: 0.3937, Val loss: 0.4854\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'checkpoints/checkpoint_latest.pt'  # or specify a specific checkpoint\n",
    "step, train_loss, val_loss = load_checkpoint(checkpoint_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a19d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation Examples:\n",
      "\n",
      "EN: Hello, how are you?\n",
      "RU: Здрово, вы возьми, как ты? \n",
      "\n",
      "EN: I love learning languages.\n",
      "RU: Я люблю изучать языки. \n",
      "\n",
      "EN: Today is a beautiful day.\n",
      "RU: Сегодня только красивый день. \n",
      "\n",
      "EN: Let's try something.\n",
      "RU: Давай попробуем что-то остарость. \n",
      "\n",
      "EN: I will be back soon.\n",
      "RU: Я скоро вернусь. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def translate(model, en_text, max_len=max_seq_length, temperature=1.0):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        src_tokens = encode_en(en_text)\n",
    "        if len(src_tokens) > max_len:\n",
    "            src_tokens = src_tokens[:max_len]\n",
    "        \n",
    "        src = torch.tensor(src_tokens, device=device).unsqueeze(0)  # [1, T]\n",
    "        \n",
    "        enc_output = model.encode(src)\n",
    "        tgt = torch.tensor([[ru_stoi[SOS_TOKEN]]], device=device)\n",
    "        \n",
    "        for _ in range(max_len):\n",
    "            dec_output = model.decode(tgt, enc_output)\n",
    "            logits = model.output_proj(model.ln_out(dec_output))\n",
    "            \n",
    "            next_logits = logits[0, -1, :] / temperature\n",
    "            probs = F.softmax(next_logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            if next_token.item() == ru_stoi[EOS_TOKEN]:\n",
    "                break\n",
    "            \n",
    "            tgt = torch.cat([tgt, next_token.unsqueeze(0)], dim=1)\n",
    "        \n",
    "        translated = decode_ru(tgt[0].tolist())\n",
    "        return translated\n",
    "\n",
    "\n",
    "print(\"Translation Examples:\\n\")\n",
    "test_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I love learning languages.\",\n",
    "    \"Today is a beautiful day.\",\n",
    "    \"Let's try something.\",\n",
    "    \"I will be back soon.\"\n",
    "]\n",
    "\n",
    "for en_text in test_sentences:\n",
    "    translation = translate(model, en_text, temperature=0.8)\n",
    "    print(f\"EN: {en_text}\")\n",
    "    print(f\"RU: {translation}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970cc78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Examples with Ground Truth:\n",
      "\n",
      "EN:        I'm just about to change that. \n",
      "RU (true): Я как раз собираюсь это изменить. \n",
      "RU (pred): Я просто просто измениться в этом меняти. \n",
      "\n",
      "EN:        The project was never completed. \n",
      "RU (true): Проект так и не был завершён. \n",
      "RU (pred): Проект никогда не было никогда не полностью. \n",
      "\n",
      "EN:        Tom didn't want to stand out. \n",
      "RU (true): Том не хотел выделяться. \n",
      "RU (pred): Том не хотел выходить из улицы. \n",
      "\n",
      "EN:        Tom did not want to stand out. \n",
      "RU (true): Том не хотел выделяться. \n",
      "RU (pred): Том не хотел выходить и не выходить. \n",
      "\n",
      "EN:        The first step is realizing that you have a problem. \n",
      "RU (true): Первый шаг заключается в том, чтобы понять, что у вас есть проблема. \n",
      "RU (pred): Первый полезна проколизиться тебе, что у тебя проблема. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Examples with Ground Truth:\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    src, tgt = val_pairs[i]\n",
    "    en_text = decode_en(src)\n",
    "    ru_true = decode_ru(tgt)\n",
    "    ru_pred = translate(model, en_text, temperature=0.5)\n",
    "    \n",
    "    print(f\"EN:        {en_text}\")\n",
    "    print(f\"RU (true): {ru_true}\")\n",
    "    print(f\"RU (pred): {ru_pred}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
